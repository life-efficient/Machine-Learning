{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn\n",
    "\n",
    "## What is it?\n",
    "\n",
    "> scikit-learn (abbreviated `sklearn`) is a __high-level machine learning library__ containing:\n",
    "> - machine learning algorithms\n",
    "> - example datasets\n",
    "> - data pre-processing & pipelines\n",
    "\n",
    "Pair that with simple API and we get a powerful & easy tool to get the job done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it didn't reach stable version (yet), it was around for __more than 10 years__ and is used throughout the industry.\n",
    "\n",
    "## Where it is used\n",
    "\n",
    "- Fast prototyping and testing ideas\n",
    "- __Part__ of more complicated pipelines\n",
    "- Often as part of Machine Learning research (if possible)\n",
    "- Widely in production for particular models such as decision trees and others that we will look at shortly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example\n",
    "\n",
    "We will introduce `sklearn` as a simple tool which allows us to easily show you concepts without delving into details.\n",
    "\n",
    "__Do not sweat over what are those algorithms right now, we will go over them in the next chapters in detail!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "As mentioned, `sklearn` provides a few ready datasets for us to use. Data is returned either in `np.array`s or in `pd.DataFrame` (we will stick to `np.array` though as it's more common).\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Load [Boston Housing Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) as `np.array` (check arguments!)\n",
    "\n",
    "Print shape of both features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# np.array instances\n",
    "X, y = datasets.load_boston(return_X_y=True)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is `Boston` house pricing dataset with `503` examples, `13` features and respective `y` targets.\n",
    "\n",
    "## Features\n",
    "\n",
    "Features consist of `13` features, among which we can find:\n",
    "- crime rate in this part of town\n",
    "- whether there is a Charles River nearby\n",
    "- how many teachers for a single pupil are in this area\n",
    "\n",
    "> As you can see features may be really creative, some may not be related to our task, while others might be in an unintuitive way.\n",
    "\n",
    "__We should always perform data analysis when we want to solve the task!__\n",
    "\n",
    "## Targets\n",
    "\n",
    "`y` (targets) is simply house price connected to those features that we would like to predict at the end of this notebook\n",
    "\n",
    "_You can read more about Boston Dataset [here](https://www.kaggle.com/c/boston-housing)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the targets are continuous, we can use them in a __regression task__ we should solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features are also floating point arrays. We will use them to train our algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Now that we have example dataset, we can create model which will learn to predict based on it.\n",
    "\n",
    "In `sklearn` it is really simple (see [documentation](https://scikit-learn.org/stable/modules/classes.html#classical-linear-regressors)).\n",
    "\n",
    "Here we will use a basic ML algorithm called __Linear Regression__ you will find more about later. \n",
    "\n",
    "> When we have some features and want to predict a continous variable (regression), linear regression is one algorithm we can use to do so\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Load [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) and set `normalize` to `True`.\n",
    "\n",
    "Also import appropriate package from `sklearn` to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "model = linear_model.LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use Sklearn's API of models\n",
    "\n",
    "`sklearn` machine learning algorithms are objects which usually follow this general convention:\n",
    "\n",
    "- `__init__(*args, **kwargs)` - here you setup your algorithm (as seen above). It controls parts of it behaviours, usually those are hyperparameters (you will learn about them in following lessons)\n",
    "- `fit(X, [y])` - train algorithm on `X` (features) and `y` (targets). In case of unsupervised algorithms there is no `y`, we will also see it later\n",
    "- `predict(X)` - pass data (previously unseen) to algorithm after `fit` was called. This gives us predictions (`y_pred`). In our case how much will a house cost.\n",
    "\n",
    "Given that we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "print(y_pred[:5], \"\\n\", y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating our model\n",
    "\n",
    "So our model predicts some values, but how well does it actually do? `sklearn` provides performance __metrics__ for us to use.\n",
    "\n",
    "You can see `sklearn`'s metrics [here](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics), in this case we will use [Mean Squared Error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error).\n",
    "\n",
    "We will go over it in detail later, but for now it is enough for you to understand the smaller the error the better.\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Import `seklarn.metrics.mean_squared_error` using `from` import syntax and\n",
    "display what is the error between true targets and predicted ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics.mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model persistance\n",
    "\n",
    "Training (`fitting`) process is often quite expensive (in time and or compute cost), while what we are after is the ability to predict on unseen data (we will see what \"unseen data\" exactly is in the next notebook).\n",
    "\n",
    "We see our model works okay and we would like to save it for later use without the need to `train` on the data again.\n",
    "\n",
    "> Model persistence means saving your machine learning algorithm currently held in RAM (Random Access Memory) to a storage (usually hard drive) from which it can be reinstantiated at any point in time\n",
    "\n",
    "As per usual it's simple with `sklearn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations, BUT\n",
    "\n",
    "You made your first machine learning model in roughly `5` lines of code.\n",
    "Why would we need anything else?\n",
    "\n",
    "### Downsides\n",
    "\n",
    "As `sklearn` is very high level it doesn't require much knowledge to use as is.\n",
    "But __we have to know more__ in order to do machine learning well. What is missing here:\n",
    "\n",
    "- Why and what for? There are many more ways (and way more correct) to do machine learning\n",
    "- Knowledge of machine learning algorithms; we have to know which one to choose for which kind of problems\n",
    "- Knowledge of possible pitfalls; machine learning can easily go wrong. We have to know more about it in order to improve our model's performance\n",
    "- In-depth knowledge of the ideas; often it might be a good idea to implement major ideas on your own\n",
    "\n",
    "__We will do all of the above__, but hopefully you can see how easy and definitely not scary it can be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "`scikit-learn` offers other goodies you can use. `Pipelines` are a way to easy join multiple machine learning related steps into one.\n",
    "\n",
    "Also everything we have seen in previous steps is employed here. `pipe` also has similar API.\n",
    "\n",
    "## Exercise\n",
    "\n",
    "Use [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) and LinearRegression inside a [`sklearn.pipeline.Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline).\n",
    "\n",
    "- PCA comes first (method for reducing the number of features)\n",
    "- Followed by LinearRegression (can have default arguments)\n",
    "- Fit this pipeline to data, `predict` on `X`\n",
    "- Display Mean Squared Error once more\n",
    "\n",
    "You can also use [`sklearn.pipeline.make_pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "# We can import Pipeline directly\n",
    "# Usually we should import subpackage though\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pca = decomposition.PCA(n_components=5)\n",
    "linear = linear_model.LinearRegression()\n",
    "\n",
    "# pipeline will run PCA model and linear model afterwards\n",
    "pipe = Pipeline(steps=[('pca', pca), ('linear', linear)])\n",
    "\n",
    "pipe.fit(X, y)\n",
    "y_pred = pipe.predict(X)\n",
    "\n",
    "print(f\"Mean Squared Error: {metrics.mean_squared_error(y, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn tips\n",
    "\n",
    "- __Always try easiest solution first__. Create a weak baseline algorithm and check how it performs. Do not go straight to the most complicated ones! It is called [Occam's Razor](https://en.wikipedia.org/wiki/Occam%27s_razor) in philosophy and machine learning also\n",
    "- Some algorithms have attributes you might be interested in. Those are usually suffixed by `_` underscore, for example `my_algorithm.interesting_attribute_`\n",
    "- Some `__init__` functions have __a lot of possible arguments__. Each of them influences how the algorithm works. But which are the most important and have the most influence? __In `sklearn` those arguments come in order from most influential to least__\n",
    "- Many `sklearn` algorithms provide `n_jobs` argument, which parallelizes `fit`, `predict` and other functions. You can use `n_jobs=-1` to use as many processes as there are virtual cores (it is often a reasonable amount), which improves performance tremendously.\n",
    "- __Use idiomatic `sklearn`__ - search the documentation, use pipelines if possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "- Fit `sklearn.Pipeline` consisting of [`VarianceThreshold`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html) and [`T-SNE`](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) as the first and second algorithm instead of PCA, followed by [`DecisionTreeRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html). Do it on [`diabetes`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes) and [`boston`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html#sklearn.datasets.load_boston) datasets.\n",
    "- Go around `scikit-learn` documentation and learn more about it. Write your own more in-depth notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- `sklearn` is a high level library used to quickly prototype solutions\n",
    "- It is not optimized for all tasks it does, many can be done in a more efficient manner\n",
    "- `API` is consistent throughout the library and each object has similiar methods like:\n",
    "    - `__init__` (to setup algorithm)\n",
    "    - `fit`\n",
    "    - `predict`\n",
    "- `sklearn.pipeline.Pipeline` is powerful tool for chaining multiple operations in a readable manner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
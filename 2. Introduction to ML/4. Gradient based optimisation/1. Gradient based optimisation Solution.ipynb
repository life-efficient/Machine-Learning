{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient based optimisation\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Calculus\n",
    "- Linear Regression Introduction\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "- Understand the concepts behind gradient based optimisation and learning\n",
    "- Implement the stochastic gradient descent (SGD) algorithm from scratch in Python\n",
    "- Implement linear regression from scratch in Python\n",
    "\n",
    "## Intro\n",
    "\n",
    "Previously, we saw how we could optimise parameters of linear regression using it's analytical solutions. This technique had some fundamental flaws though...\n",
    "- It is available only for special cases of machine learning methods, hence __isn't general method__\n",
    "- Computationally infeasible for large datasets and a lot of features\n",
    "\n",
    "This notebook will walk through how we can use **gradient based optimisation** as another technique to find model parameterisations that perform well.\n",
    "\n",
    "Gradient based optimisation is not exclusively used in machine learning, it is a technique used for optimising all kinds of functions in all kinds of domains.\n",
    "\n",
    "> We are going to use gradient based optimisation to minimise the criterion of our ML algorithms\n",
    "\n",
    "To get your mind running, gradient based optimisation looks a bit like the following diagram. In our case, $f(w)$ would represent the criterion that we want to minimise, which varies with the model parameters ($w$ & $b$ for linear regression):\n",
    "\n",
    "![](images/gradient_descent_intuition.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is gradient based optimisation all about?\n",
    "\n",
    "Our loss is just a mathematical function that depends on the parameters of our model (for example, we used the mean squared error (MSE) loss function in the previous notebooks).\n",
    "We would like to move our parameters to the point where this loss is minimised.\n",
    "\n",
    "> If we were to evaluate the value of our loss for every possible different parameterisation of our model, we would produce a **loss surface**. \n",
    "\n",
    "We would like to find the lowest point on this surface. \n",
    "- At this point it will have a gradient (steepness) of zero with respect to the parameters.\n",
    "- As our parameters move away from that minima in some direction, the gradient will increase in that direction.\n",
    "\n",
    "To get back to the minima, we should hence __move our weights in the opposite direction to gradient__ (simply subtract it).\n",
    "\n",
    "![](./images/grad-based-optim.jpg)\n",
    "\n",
    "## Numerical example\n",
    "\n",
    "Below is an example that shows the direction to shift a parameter $W$, initialised as $w=4$, for a surface given by:\n",
    "\n",
    "$$\n",
    "L=(W-2)^2\n",
    "$$ \n",
    "\n",
    "At this point on the surface, the gradient of the loss with respect to this parameter is positive, so we should shift it in the negative direction to push it closer the the optima.\n",
    "\n",
    "![](images/sgd_numerical_example.jpg)\n",
    "\n",
    "Below is a more complex potential loss surface which has more than one parameter (vertical axis represents loss value, others represent parameter values). In reality, we will often have many more features, and we won't be able to visualise the loss surface as we would need more than 3 dimensions.\n",
    "\n",
    "<img style=\"height: 200px\" src='./images/comp-loss-surface.png'/>\n",
    "\n",
    "> **Note: because gradient based optimisation depends on us computing the gradient of the loss function, our loss function and model must be fully differentiable (they must be a smooth, continuous function).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "\n",
    "Gradient descent is an iterative, gradient based optimisation technique. \n",
    "\n",
    "That is, it is a technique for finding the minima (or maxima) of a function, and it does so by iteratively moving the parameters downhill, in the opposite direction to the gradient of the surface.\n",
    "\n",
    "![](images/gradient_descent_intuition.jpg)\n",
    "\n",
    "### The learning rate, $\\alpha$\n",
    "\n",
    "We will update our parameters by shifting them in the opposite direction to the gradient. But by what amount should we shift them in that direction?\n",
    "\n",
    "> Learning rate $\\alpha$ (abbreviated often `lr` in source code) __multiplies gradient__ to decrease (usually) or increase it's magnitude\n",
    "\n",
    "`step_size` hence is `gradient` multiplied by our `lr`.\n",
    "\n",
    "#### Too small `lr`\n",
    "\n",
    "There are a few things that may happen if we get it wrong:\n",
    "- If `lr` is too small our convergence __might take a long time__\n",
    "- We might get stuck in local minimas or saddle points (will go over that in a second)\n",
    "\n",
    "![title](images/low-lr.jpg)\n",
    "\n",
    "#### Too large `lr`\n",
    "\n",
    "- If `lr` is too large, we may jump out of minimum\n",
    "- Instead of __converging__ we might __diverge__\n",
    "\n",
    "![title](images/high-lr.jpg)\n",
    "\n",
    "So we include the learning rate to scale up/down the size of the steps. \n",
    "\n",
    "> The learning rate should most likely be less than 1 though (see challenges for different example)\n",
    "\n",
    "You should play around with the learning rate and adjust it until your model converges.\n",
    "\n",
    "![title](images/convergence.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local optima\n",
    "\n",
    "Don't stress too much about it\n",
    "\n",
    "Yes, in the case where we are trying to minimise a function with respect to 1 or 2 parameters, gradient descent is prone to getting stuck in local optima.\n",
    "\n",
    "But most of the models that are useful in practice depend on many more parameters (neural networks can easily have millions).\n",
    "\n",
    "> As the number of parameters increase, it becomes exponentially unlikely that any parameterisation is at a minima, but is rather a saddle point, and so there is still an indication of how to improve.\n",
    "\n",
    "Furthermore, __in practice we often find that we don't need to find a global optima__\n",
    "Local optima can be good enough to reach our required performance.\n",
    "\n",
    "On top of this, we can attempt to counter getting stuck in local optima by using different optimisation algorithms, such as [gradient descent with (Nesterov) momentum](https://distill.pub/2017/momentum/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "\n",
    "The diagrams shown above visualise how a single parameter affects the loss. \n",
    "\n",
    "A model with multiple parameters (such as a weight and a bias, or multiple weights) would be optimised in the same way - we would just have more of these functions. \n",
    "\n",
    "> We can think of each of the graphs as a cross section through a **loss surface**. \n",
    "\n",
    "A loss surface is shown below which visualises how the criterion of a model might vary with both parameters.\n",
    "\n",
    "$$\n",
    "L = w_1^4 + w_2^2\n",
    "$$\n",
    "\n",
    "<img style=\"height: 300px\" src='images/x2x4.png'/>\n",
    "\n",
    "![](images/multivariate_sgd.jpg)\n",
    "\n",
    "If we know the function that the loss is computed from and it is differentiable, then we can calculate the derivative of the loss with respect to our model parameters:\n",
    "- by hand (pretty tiring - but we're gonna do it)\n",
    "- using an automatic differentiation graph (what we're gonna do later when we get to deep learning)\n",
    "\n",
    "After that we can iteratively move each parameter in the direction of the opposite gradient. "
   ]
  },
  {
   "source": [
    "## Firstly, a helper function\n",
    "\n",
    "We'll use this code shortly to visualise how training is progressing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_loss(losses):\n",
    "    \"\"\"Helper function for plotting loss against epoch\"\"\"\n",
    "    plt.figure() # make a figure\n",
    "    plt.ylabel('Cost')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.plot(losses) # plot costs\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "## 1. The data\n",
    "\n",
    "Run the cells below to get the data and plot it"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, model_selection\n",
    "from aicore.ml import data\n",
    "\n",
    "# Use `data.split` in order to split the data into train, validation, test\n",
    "(X_train, y_train), (X_validation, y_validation), (X_test, y_test) = data.split(\n",
    "    datasets.load_boston(return_X_y=True)\n",
    ")\n",
    "X_train, X_validation, X_test = data.standardize_multiple(X_train, X_validation, X_test)\n"
   ]
  },
  {
   "source": [
    "## 2. The model\n",
    "\n",
    "Here's the same model we implemented before"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, optimiser, n_features): # initalize parameters \n",
    "        self.w = np.random.randn(n_features) ## randomly initialise weight\n",
    "        self.b = np.random.randn() ## randomly initialise bias\n",
    "        self.optimiser = optimiser\n",
    "        \n",
    "    def predict(self, X): # how do we calculate output from an input in our model?\n",
    "        ypred = X @ self.w + self.b ## make a prediction using a linear hypothesis\n",
    "        return ypred # return prediction\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        all_costs = [] ## initialise empty list of costs to plot later\n",
    "        for epoch in range(self.optimiser.epochs): ## for this many complete runs through the dataset    \n",
    "\n",
    "            # MAKE PREDICTIONS AND UPDATE MODEL\n",
    "            predictions = self.predict(X) ## make predictions\n",
    "            new_w, new_b = self.optimiser.step(self.w, self.b, X, predictions, y) ## calculate updated params\n",
    "            self._update_params(new_w, new_b) ## update model weight and bias\n",
    "            \n",
    "            # CALCULATE LOSS FOR VISUALISING\n",
    "            cost = mse_loss(predictions, y) ## compute loss \n",
    "            all_costs.append(cost) ## add cost for this batch of examples to the list of costs (for plotting)\n",
    "\n",
    "        plot_loss(all_costs)\n",
    "        print('Final cost:', cost)\n",
    "        print('Weight values:', self.w)\n",
    "        print('Bias values:', self.b)\n",
    "\n",
    "    \n",
    "    def _update_params(self, new_w, new_b):\n",
    "        self.w = new_w ## set this instance's weights to the new weight value passed to the function\n",
    "        self.b = new_b ## do the same for the bias"
   ]
  },
  {
   "source": [
    "## 3. The criterion\n",
    "\n",
    "Let's remind ourselves the formula:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    L_{mse} = \\frac{1}{N}\\sum_{i}^{N}(\\hat{y_i} - y_i)^2\n",
    "\\end{equation}\n",
    "$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_hat, labels): # define our criterion (loss function)\n",
    "    errors = y_hat - labels ## calculate errors\n",
    "    squared_errors = errors ** 2 ## square errors\n",
    "    mean_squared_error = sum(squared_errors) / len(squared_errors) ## calculate mean \n",
    "    return mean_squared_error # return loss"
   ]
  },
  {
   "source": [
    "## 4. The optimiser: Gradient descent\n",
    "\n",
    "With linear regression, you can swap out different optimisers and stick with the same model, data and criterion.\n",
    "\n",
    "### Implementing gradient descent from scratch\n",
    "\n",
    "Below is a derivation for computing the rate of change (gradient) of the loss with respect to our model parameters when using a linear model and the mean squared error loss function.\n",
    "![title](images/NN1_single_grad_calc.jpg)\n",
    "\n",
    "Complete the class below to return the derivative of our loss w.r.t the weight and bias by implementing the above equations in code."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SGDOptimiser:\n",
    "    def __init__(self, lr, epochs):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def _calc_deriv(self, features, predictions, labels):\n",
    "        m = len(labels) ## m = number of examples\n",
    "        diffs = predictions - labels ## calculate errors\n",
    "        dLdw = 2 * np.sum(features.T * diffs).T / m ## calculate derivative of loss with respect to weights\n",
    "        dLdb = 2 * np.sum(diffs) / m ## calculate derivative of loss with respect to bias\n",
    "        return dLdw, dLdb ## return rate of change of loss wrt w and wrt b\n",
    "\n",
    "    def step(self, w, b, features, predictions, labels):\n",
    "        dLdw, dLdb = self._calc_deriv(features, predictions, labels)\n",
    "        new_w = w - self.lr * dLdw\n",
    "        new_b = b - self.lr * dLdb\n",
    "        return new_w, new_b\n",
    "    "
   ]
  },
  {
   "source": [
    "## Putting it all together\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "optimiser = SGDOptimiser(lr=learning_rate, epochs=num_epochs)\n",
    "model = LinearRegression(optimiser=optimiser, n_features=X_train.shape[1])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "## `sklearn` example\n",
    "\n",
    "`sklearn` packs everything we just did above into it's simple [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) API."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression_model = LinearRegression() ## instantiate the linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(model, X, y):\n",
    "    return mse_loss(\n",
    "        model.predict(X),\n",
    "        y\n",
    "    )\n",
    "\n",
    "print(f\"Training loss before fit: {calculate_loss(model, X_train, y_train)}\")\n",
    "print(\n",
    "    f\"Validation loss before fit: {calculate_loss(model, X_validation, y_validation)}\"\n",
    ")\n",
    "print(f\"Test loss before fit: {calculate_loss(model, X_validation, y_validation)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linear_regression_model.fit(X_train, y_train) ## fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will do the same but fit the model for some epochs and see the loss after training, validation and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Training loss after fit: {calculate_loss(model, X_train, y_train)}\")\n",
    "print(f\"Validation loss after fit: {calculate_loss(model, X_validation, y_validation)}\")\n",
    "print(f\"Test loss after fit: {calculate_loss(model, X_validation, y_validation)}\")"
   ]
  },
  {
   "source": [
    "We can also take a look into the final parameters of the model when using sklearn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('final weights:', model.coef_)\n",
    "print('final bias:', model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why gradient based optimisation?\n",
    "\n",
    "> Gradient based optimisation uses __heuristics__ which indicate how to improve w.r.t. loss (e.g. to minimize it).\n",
    "\n",
    "There are other available options (like analytical solutions, sometimes), and we went through the shortcomings.\n",
    "\n",
    "We could also search parameters __randomly__, but\n",
    "\n",
    "- our search region may not contain an optimal parameterisation for our model. For example, if we allowed bias `[-10, 10]` we would never obtain the solution \n",
    "- exponential increase in runtime with each additional parameter\n",
    "- no feedback from the process (gradient is our feedback here)\n",
    "\n",
    "__There is still one question left unanswered__:\n",
    "\n",
    "> What should we do when our data does not fit into memory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why not pass the whole dataset through each prediction?\n",
    "\n",
    "We know that to perform gradient based optimisation we need to pass inputs through the model (forward pass), and then compute the loss and find how it changes with respect to each of our model's parameters (backward pass). \n",
    "\n",
    "Modern datasets can be absolutely huge. This means that the forward pass can take a long time, as the function which our model represents has to be applied to each and every input given to it for a forward pass.\n",
    "\n",
    "> Passing the full dataset through the model at each pass is called **full batch gradient descent**.\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "- Whole dataset may harm generalization and lead to overfitting\n",
    "- Might be slower (slower memory access, more cache misses)\n",
    "\n",
    "\n",
    "## Why not a single datapoint for each update?\n",
    "\n",
    "Let's assume we will pass a single example to our network and backpropagate based on that.\n",
    "Here is what will probably happen:\n",
    "- `gradient` will vary __A LOT__ - single example is usually uninformative for our whole task\n",
    "- `outliers` (special data points, which could as well be noise and are totally non-representative of the task) will affect our dataset way more\n",
    "\n",
    "Passing single examples through the model at each pass is called **online stochastic gradient descent**.\n",
    "\n",
    "What happens if, for some reason (memory constraints or examples come in as stream), we have to go with this approach?\n",
    "\n",
    "> Do related challenges\n",
    "\n",
    "but moving on...\n",
    "\n",
    "\n",
    "## Mini-batch gradient descent\n",
    "\n",
    "The modern way to do training is neither whole dataset nor fully stochastic (single datapoint). \n",
    "\n",
    "Instead we use mini-batch training:\n",
    "\n",
    "> Sample several (usually `64-2048`, depending on memory) datapoints to compute a sample of the gradient\n",
    "\n",
    "Most optimisation algorithms converge much faster if they are allowed to rapidly compute approximate gradients rather than slowly compute exact gradients. \n",
    "\n",
    "The size of the mini-batch is called the **batch size** and this technique is currently most widely used (especially in neural network).\n",
    "\n",
    "### Advantages of mini-batch gradient descent\n",
    "\n",
    "- We can adjust the size to fit memory on most machines\n",
    "- Is faster (easier to parallelize if multiple of `2`)\n",
    "- Improves generalization as each batch is a little noisy\n",
    "\n",
    "## Challenge\n",
    "\n",
    "We will implement a `DataLoader` class which takes a few datasets and `yield`s batches of data, then change your linear regression model to work with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why data shuffling?\n",
    "\n",
    "It is especially important for __large and more complex models__ (neural networks). If we didn't do that we might risk the following:\n",
    "\n",
    "- same updates are provided to the model at each batch. We want to estimate the total average, hence batches have to be different\n",
    "- model \"memorizes\" batch (happens in neural networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges\n",
    "\n",
    "- What is [gradient accumulation](https://towardsdatascience.com/gradient-accumulation-overcoming-memory-constraints-in-deep-learning-36d411252d01) and what problem does it solve?\n",
    "- What is [super convergence](https://medium.com/@abdelrhman.d/exploring-super-convergence-5fb3050b4667)?\n",
    "- Our `DataLoader` will not always return full dataset (check how it behaves for data with `100` samples and `batch_size=51`). Why is \"leaving last batch out\" fine for training? Why isn't it fine for validation? Make the dataloader return all data at each pass.\n",
    "- Create `LinearRegression` which has `predict` working on batches as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Linear Regression can be seen as an acyclic directed graph of operations\n",
    "- Any differentiable model can be backpropagated using graph\n",
    "- We do backprop in order to populate model's parameters/weights with gradient\n",
    "- __Optimizer__ is an object which given parameter's current values and their gradients w.r.t. some value (usually loss) try to minimize this value by altering parameter's with gradients in some way\n",
    "- __Storchastic Gradient Descent (SGD)__ is basic optimization technique which simply subtracts gradient from parameter's value __multiplied by `learning rate`__\n",
    "- __Learning rate (`lr`)__ decides the magnitude of step taken by optimizer and is present in most optimizers\n",
    "- __Mini-batch stochastic gradient descent__ is when you take parts of dataset and push through your model instead of single example or whole dataset at once. Saves memory and helps in generalization\n",
    "- __Shuffling is necessary for mini-batches__ as it better mimicks overall gradient of the dataset and makes model resistant to noise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
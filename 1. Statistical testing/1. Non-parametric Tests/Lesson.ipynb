{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-parametric Tests\n",
    "\n",
    "In an ideal world, we could use the tests we have described above as well as others under similar assumptions, assuming normality and smooth sailing. In fact, because of how data is generally distributed in nature and the CLT, we can often get away with this assumption even when the distribution of our data is not exactly normal. There are also various methods of ensuring that your data follows approximately a normal distribution or trying to transform your data to be normally distributed. But every now and then, we may observe cases where the underlying distribution diverges too much from normality, and may not follow other useful distributions. Hence, we must touch upon the concept of __non-parametric tests__.\n",
    "\n",
    "__Parametric tests__ are statistical tests that make some kind of assumption about the underlying distribution of the data, the most common one being of normality. When these assumptions are no longer valid, we turn to __non-paramtric tests__, also referred to as __distribution-free tests.__ Rather than testing about the means of our data, non-parametric tests test about the median of our data.\n",
    "\n",
    "Let us consider the non-parametric test most commonly used instead of the one-sample t-test: the __Wilcoxon signed rank test.__ We will use this non-parametric test on the data we used for the one-sample t-test: the Amazon offset delivery time data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Formulate a hypothesis\n",
    "As we are no longer assuming the data has a normal underlying distribution, we will now test about the median of the data:\n",
    "\n",
    "$\\mathbf{H_{0}}$: The median offset time is 30 minutes\n",
    "\n",
    "$\\mathbf{H_{a}}$: The median offset time is not 30 minutes\n",
    "\n",
    "### 2. Find the appropriate statistical test\n",
    "As mentioned, since we are no longer assuming our data follows a normal distribution, we will be using a two-tailed Wilcoxon-signed rank test.\n",
    "\n",
    "### 3. Choose a significance level\n",
    "As before, we will use a significance level of $\\alpha=0.1$.\n",
    "\n",
    "### 4. Collect data and compute test statistic\n",
    "We will read the data from our file once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reading data from file\n",
    "offset_data = pd.read_csv(\"amazon_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this data, assuming our median to be $\\mu_{0}=30$ minutes, to determine whether the median is truly 30 minutes. The test statistic for a Wilcoxon signed rank test is the $\\mathbf{s_{+}}$ statistic, which can be calculated as follows:\n",
    "1. Find the difference between every data point from the assumed median\n",
    "2. Find the absolute value of each of those differences and rank them in ascending order\n",
    "3. Compute $s_{+}$ as the sum of the rank of the positive differences\n",
    "\n",
    "These steps are shown below for our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_plus: 76\n",
      "         data  differences  absolute differences signs  ranks\n",
      "0   57.925694    27.925694              0.232974     +      1\n",
      "1   40.574152    10.574152              0.970240     +      2\n",
      "2   30.232974     0.232974              1.696030     +      3\n",
      "3   20.853756    -9.146244              1.737354     -      4\n",
      "4   21.355134    -8.644866              4.707712     -      5\n",
      "5   14.037427   -15.962573              8.644866     -      6\n",
      "6   31.696030     1.696030              9.054106     -      7\n",
      "7    5.784466   -24.215534              9.146244     -      8\n",
      "8   65.960599    35.960599             10.574152     +      9\n",
      "9   50.994944    20.994944             15.962573     -     10\n",
      "10  30.970240     0.970240             17.649881     -     11\n",
      "11   9.928767   -20.071233             20.071233     -     12\n",
      "12  25.292288    -4.707712             20.994944     +     13\n",
      "13  12.350119   -17.649881             24.215534     -     14\n",
      "14  28.262646    -1.737354             24.300015     +     15\n",
      "15  20.945894    -9.054106             27.925694     +     16\n",
      "16  54.300015    24.300015             35.960599     +     17\n"
     ]
    }
   ],
   "source": [
    "# Wilcoxon Signed Rank Test\n",
    "median = 30\n",
    "data = offset_data[\"0\"] # ascending order\n",
    "diffs = data - median\n",
    "\n",
    "# Tracking sign of each difference\n",
    "signs = dict()\n",
    "absolute_diffs = np.array([])\n",
    "for diff in diffs:\n",
    "    absolute_diffs = np.append(absolute_diffs, np.abs(diff))\n",
    "    if diff < 0:\n",
    "        signs[np.abs(diff)] = '-'\n",
    "    else:\n",
    "        signs[np.abs(diff)] = '+'\n",
    "\n",
    "# Sorting absolute differences in ascending order\n",
    "sorted_absolute_diffs = np.sort(absolute_diffs)\n",
    "\n",
    "# Computing s+ statistic\n",
    "s_plus = 0\n",
    "for idx, diff in enumerate(sorted_absolute_diffs):\n",
    "    if signs[diff] == '+':\n",
    "        s_plus += idx+1\n",
    "\n",
    "# Creating structured dataframe\n",
    "data_dic = {\"data\": data}\n",
    "column_titles = [\"differences\", \"absolute differences\", \"signs\", \"ranks\"]\n",
    "ordered_signs = [signs[sorted_absolute_diff] for sorted_absolute_diff in sorted_absolute_diffs]\n",
    "data_columns = [diffs, sorted_absolute_diffs, ordered_signs, range(1, 18)]\n",
    "processed_data = pd.DataFrame(data_dic)\n",
    "for column_title, column_data in zip(column_titles, data_columns):\n",
    "    processed_data[column_title] = column_data\n",
    "print(\"s_plus:\", s_plus)\n",
    "print(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also confirm our results with external Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_plus: 76.0\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Wilcoxon Signed Rank Test via scipy.stats\n",
    "s_plus, p = stats.wilcoxon(diffs, alternative=\"two-sided\")\n",
    "print(\"s_plus:\", s_plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Determine the p-value (probability)/critical value\n",
    "Given the statistic computed and the known parameters we can use the Wilcoxon signed rank table to determine our critical value for a two-tailed test with $n=17$, which is $c=41$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Reject/accept null hypothesis\n",
    "From how we set up, the maximum possible statistic you can get is the sum of all possible ranks:\n",
    "$$s_{+,max} = 1 + 2 + 3 + ... + n = \\frac{n}{2}(n-1)$$\n",
    "\n",
    "Therefore, for a two-tail test, the rejection region is given by $s_{+}\\leq 41$ and $s_{+}\\geq 95$. Given that our statistic is $s_{+} = 76$, we cannot reject and thus must accept the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Make a decision\n",
    "Just as observed before with the mean of our data for the one-sample t-test, the median our data does not show any significant difference from 30 minutes. Therefore, even by using a non-parametric test, we arrived at the same conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just shown that we can arrive by using a non-parametric test, we can test the same things as for a parametric test. A logical question to ask is: \"if non-parametric tests can always be applied regardless of the underlying distributions, why don't we always use them instead of parametric tests?\". The first reason is that __parametric tests have much more statistical power than non-parametric tests.__ This means that you are more likely to determine a significant effect if there is one by carrying out parametric tests.\n",
    "\n",
    "The second reason is that even though non-parametric tests do not make any assumptions about the underlying distribution, they do make other assumptions about the data at hand. For instance, when comparing groups, non-parametric tests may not provide valid results if the dispersion of the data for each group is not similar, which is not the case for parametric tests as we have seen for the one-way ANOVA.\n",
    "\n",
    "Some more comparable non-parametric tests are shown below:\n",
    "\n",
    "| Parametric test of means | Non-parametric test of medians       |\n",
    "|--------------------------|--------------------------------------|\n",
    "| one-sample t-test        | one-sample Wilcoxon signed rank test |\n",
    "| two-sample t-test        | Mann-Whitney test                    |\n",
    "| One-way ANOVA            | Kruskal Wallis, Mood's median test   |\n",
    "\n",
    "There are more parametric and non-parametric tests out there that we have not covered today that may be applied to different to contexts, as well as other applications of the same tests covered today. However, all of them will work under the same framework and logic learned through this section."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

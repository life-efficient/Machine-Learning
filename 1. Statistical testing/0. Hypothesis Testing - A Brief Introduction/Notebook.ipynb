{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Hypothesis Testing\r\n",
    "\r\n",
    "As data scientists, we often find the need to make decisions based on the data we have collected. After obtaining our statistics, we can have a decent _feeling_ or _opinion_ on whether our data is valid and shows significant results. But how can we make more objective decisions based on our results?\r\n",
    "\r\n",
    "Thus arises the need for __statistical hypothesis testing__, also known as __confirmatory data analysis__. It provides us with a framework for using statistical and probabilistic methods on our data to be able to determine the significance of our results. \r\n",
    "\r\n",
    "We assume that you are already familiar with basic statistics terms, such as mean, standard deviation, or mean square error. Otherwise, refer to the Data Wrangling module in the Data Engineering content.\r\n",
    "\r\n",
    "We will finish this notebook with one of the most popular applications of hypothesis testing: __A/B Testing__"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Null & Alternative Hypotheses\r\n",
    "\r\n",
    "In hypothesis testing, we have to construct two opposing hypotheses. The first one is known as the __null hypothesis__ ($\\mathbf{H_{0}}$) and is the hypothesis you are trying to __reject__. The second one is known as the __alternative hypothesis__ ($\\mathbf{H_{A}}$), and is the hypothesis you are trying to __support__. Within this framework, we assume the null hypothesis is true, and use statistical methods to determine whether our evidence is conclusive __enough__ to reject the null hypothesis, and support the alternative hypothesis.\r\n",
    "\r\n",
    "This is a similar framework to the approach used in court cases. During a trial, the outlook is that a person is 'innocent until proven guilty'. This means that, in this case:\r\n",
    "- $\\mathbf{H_{0}}$: The person is innocent\r\n",
    "- $\\mathbf{H_{A}}$: The person is guilty\r\n",
    "\r\n",
    "And the prosecuting lawyers will use various pieces of evidence to reject $\\mathbf{H_{0}}$. \r\n",
    "\r\n",
    "In general, we can think of the null hypothesis as being 'your evidence _does not_ suggest what you think' and the alternative as being 'your evidence _does_ suggest what you think'. You assume your evidence _does not_ contribute anything new until you have statistical measures that suggest your evidence _does_ contribute to something new.\r\n",
    "\r\n",
    "As we will see later on, we will have different levels of statistical significance for our data. We can set thresholds to determine at which point of significance we reject our null hypothesis, but this threhsold depends on the context of the problem and is up for data scientists and statisticians to determine. How do we go about determining these thresholds? We will see that shortly, first, let's talk about three very important concepts regarding hypothesis testing. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### __Significance level (α)__\r\n",
    "\r\n",
    "The significance level, also denoted as alpha or α, is the probability of rejecting the null hypothesis when it is true. Generally, we use the significance value of 0.05\r\n",
    "\r\n",
    "### __p-Value__\r\n",
    "\r\n",
    "It is the probability of obtaining the test results considering the null hypothesis is true. In other words, it is the probability that the difference between the two values is just because of random chance. The smaller the p-value, the stronger the chances to reject the null hypothesis. For the significance level of 0.05, if the p-value is lesser than it hence we can reject the null hypothesis.\r\n",
    "\r\n",
    "### __Confidence Interval__\r\n",
    "\r\n",
    "The confidence interval is an observed range in which a given percentage of test outcomes fall. We manually select our desired confidence level at the beginning of our test. Do not confuse it with the confidence level, which is $(1 - α)$\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Type I & Type II Errors\r\n",
    "\r\n",
    "Statistical hypothesis testing is meant to help data scientists and statisticians to reach a more objective conclusion based on how statistically significant our results are. But the issue arises when we have to determine a given threshold for significance. For instance, when do we reject our null hypothesis? at 70% certainty? 95% certainty? 99.9% certainty? To choose an appropriate _threshold_ of certainty, we have to understand to context of our experiment.\r\n",
    "\r\n",
    "Let us go back to the analogy of a court case. Since in a court case, you can never have 100% certainty, there is always a probability of wrongully arresting an innocent person or letting a guilty person walk free. Consider the possibilities in the table below.\r\n",
    "\r\n",
    "\r\n",
    "<center>\r\n",
    "\r\n",
    "|                     | Court Case Outcomes |                     |\r\n",
    "|---------------------|---------------------|---------------------|\r\n",
    "|                     | Truly Innocent      | Truly Guilty        |\r\n",
    "| Determined Innocent | Correct             | Failed imprisonment |\r\n",
    "| Determined Guilty   | Wrongful arrest     | Correct             |\r\n",
    "\r\n",
    "</center>\r\n",
    "\r\n",
    "There are two distinct types of mistakes that can happen in the decision process. When we arrest an innocent person, we have committed a __Type I error__, where we __wrongfully reject the null hypothesis (false positive)__. When we fail to arrest a guilty person, we have commited a __Type II error__, where we __wrongfully accept the null hypothesis (false negative)__. In general, when we aim to minimize the likelihood one type of error, the likelihood of the other error increases. In this case, if we are highly strict and demand a very high degree of certainty, we will minimize the number of wrongful arrests (Type I), but it also becomes more likely to not arrest someone who is guilty (Type II). On the other hand, if judges demand a lesser degree of certainty, we will arrest more guilty people, but are also more likely to wrongfully arrest an innocent person.\r\n",
    "\r\n",
    "In our modern judicial system, we believe that the accused is innocent until proven guilty, and that wrongful imprisionment is worse than letting a guilty person walk free."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<center>\r\n",
    "<p><img src='images/free.png' width=150><img src='images/balance.png' width=250><img src='images/arrested.png' width=250></p>\r\n",
    "</center>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Therefore, we require a high degree of certainty to arrest someone, and put our efforts into minimizing the number of wrongful arrests. This principle applies to other contexts of hypothesis testing: given the context we use our best judgement to determine what type of errors we want to minimize, and set our parameters and hypotheses accordingly."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# A/B Testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A/B testing is a basic control experiment. It is a way to compare the two versions of a variable to find out which performs better in a controlled environment.\r\n",
    "\r\n",
    "For instance, you have made certain changes to your website recently. Unfortunately, you have no way of knowing with full accuracy how the next 100,000 people who visit your website will behave. That is the information we cannot know today, and if we were to wait until those 100,000 people visited our site, it would be too late to optimize their experience.\r\n",
    "\r\n",
    "You can divide the products into two parts – A and B. Here A will remain unchanged while you make significant changes in B’s packaging. Now, on the basis of the response from customer groups who used A and B respectively, you try to decide which is performing better.\r\n",
    "\r\n",
    "<p align=center><img src=images/ab_test.png width=500></p>\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The objective here is to check which option brings higher traffic on the website i.e the conversion rate. We will use A/B testing and collect data to analyze which option performs better."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Formulate an hypothesis\r\n",
    "\r\n",
    "$\\mathbf{H_{0}}$: From an A/B test perspective, the null hypothesis states that there is no difference between the control and variant groups. Here our $\\mathbf{H_{0}}$ is \"there is no difference in the conversion rate in customers receiving option A and B\".\r\n",
    "\r\n",
    "$\\mathbf{H_{a}}$: The alternative hypothesis is what you might hope that your A/B test will prove to be true. In our example, the $\\mathbf{H_{a}}$ is \"the conversion rate of option B is higher than those who receive option A\".\r\n",
    "\r\n",
    "We have to collect enough evidence through our tests to reject the null hypothesis."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Control Group and Test Group\r\n",
    "\r\n",
    "The next step is to decide the group of customers that will participate in the test. Here we have two groups – The Control group, and the Test (variant) group.\r\n",
    "\r\n",
    "The Control Group is the one that will receive newsletter A and the Test Group is the one that will receive newsletter B."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Statistical significance\r\n",
    "\r\n",
    "How can we conclude from here that the Test group is working better than the control group?\r\n",
    "\r\n",
    "For rejecting our null hypothesis we have to prove the Statistical significance of our test.\r\n",
    "\r\n",
    "There are two types of errors that may occur in our hypothesis testing:\r\n",
    "\r\n",
    "1. __Type I error__: We reject the null hypothesis when it is true. That is we accept the variant B when it is not performing better than A\r\n",
    "2. __Type II error__: We failed to reject the null hypothesis when it is false. It means we conclude variant B is not good when it performs better than A\r\n",
    "\r\n",
    "That means the difference between your control version and the test version is not due to some error or random chance. To prove the statistical significance of our experiment we can use a two-sample T-test.\r\n",
    "\r\n",
    "The two–sample t–test is one of the most commonly used hypothesis tests. It is applied to compare whether the average difference between the two groups.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "import matplotlib.pylab as plt\n",
    "data= pd.read_csv(\"https://aicore-files.s3.amazonaws.com/Data-Science/ab_data.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let’s plot the distribution of target and control group:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(\"Test Plots\")\n",
    "sns.distplot(data.Conversion_A, label='A')\n",
    "sns.distplot(data.Conversion_B, label='B')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use scipy to calculate the t-test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "t_stat, p_val= ss.ttest_ind(data.Conversion_B,data.Conversion_A)\n",
    "print(f'The t-test value is {t_stat}, and the p-value is {p_val}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The t-test value is 3.78736793091929, and the p-value is 0.000363796012828762\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, our p-value is less than the significance level i.e 0.05. Hence, we can reject the null hypothesis. This means that in our A/B testing, option B is performing better than option A. So our recommendation would be to replace our current option with B to bring more traffic on our website."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are many tools available for conducting A/B testing but being a data scientist you must understand the factors working behind it. Also, you must be aware of the statistics in order to validate the test and prove its significance."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "interpreter": {
   "hash": "ad8bebc098a042dc0df4e42fc2ecc8fff0bd7b8741641ce29007c29766dadbe0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}